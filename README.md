# Shannon-Fano Coding

In the field of data compression, Shannonâ€“Fano coding, named after Claude Shannon and Robert Fano, is a name given to two different but related techniques for constructing a prefix code based on a set of symbols and their probabilities (estimated or measured).

It assigns shorter codes to more frequent symbols and longer codes to less frequent symbols.

## Example
Consider a text file that uses only five characters (A, B, C, D, E)

|     Character    |      A    |      B    |      C    |      D    |      E    |
|:----------------:|:---------:|:---------:|:---------:|:---------:|:---------:|
|     Frequency    |     17    |     12    |     12    |     27    |     32    |

=> Total Characters in the file = 100

#### Step 1 : Find probability. 

|     Character    |     Frequency    |     Probability    |
|:----------------:|:----------------:|:------------------:|
|         A        |         17       |         0.17       |
|         B        |         12       |         0.12       |
|         C        |         12       |         0.12       |
|         D        |         27       |         0.27       |
|         E        |         32       |         0.32       |

#### Step 2 : Sort.

|     Character    |     Frequency    |     Probability    |
|:----------------:|:----------------:|:------------------:|
|         E        |         32       |         0.32       |
|         D        |         27       |         0.27       |
|         A        |         17       |         0.17       |
|         B        |         12       |         0.12       |
|         C        |         12       |         0.12       |

#### Step 3 : Partition #1.

|     Character    |     Probability    |          |
|:----------------:|:------------------:|:--------:|
|         E        |         0.32       |     0    |
|         D        |         0.27       |     0    |
|         A        |         0.17       |     1    |
|         B        |         0.12       |     1    |
|         C        |         0.12       |     1    |

#### Step 4 : Partition #2.

|     Character    |     Probability    |          |          |
|:----------:|:-----------:|:--------:|:--------:|
|      E     |     0.32    |     0    |     0    |
|      D     |     0.27    |     0    |     1    |
|      A     |     0.17    |     1    |     0    |
|      B     |     0.12    |     1    |     1    |
|      C     |     0.12    |     1    |     1    |

#### Step 5 : Partition #3. Final Encoding. 
|     Character    |     Probability    |          |          |          |
|:----------:|:-----------:|:--------:|:--------:|:--------:|
|      E     |     0.32    |     0    |     0    |          |
|      D     |     0.27    |     0    |     1    |          |
|      A     |     0.17    |     1    |     0    |          |
|      B     |     0.12    |     1    |     1    |     0    |
|      C     |     0.12    |     1    |     1    |     1    |

